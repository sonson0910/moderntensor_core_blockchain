#!/usr/bin/env python3
"""
Slot Coordinator for Synchronized Validator Consensus

This module provides SlotCoordinator class that ensures all validators:
- Stop task assignment at synchronized cutoff times
- Coordinate phase transitions (task assignment ‚Üí execution ‚Üí consensus ‚Üí metagraph update)
- Perform P2P consensus with proper waiting mechanisms
- Update metagraph together after reaching consensus

Key Features:
- File-based coordination using JSON files
- Majority consensus (2/3 validators)
- Precise timing based on blockchain epochs
- Automatic cleanup of old coordination files
"""

import asyncio
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum
import logging

logger = logging.getLogger(__name__)

# Constants
# Dynamic EPOCH_START - set to 1 hour before current time to ensure proper slot timing
import time as time_module
EPOCH_START = int(time_module.time()) - 3600  # 1 hour before current time
EXPECTED_VALIDATORS = ["validator_1", "validator_2", "validator_3"]
MAJORITY_THRESHOLD = 2  # Need 2 out of 3 validators
CONSENSUS_CHECK_INTERVAL = 5  # Check every 5 seconds


class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder that handles non-serializable objects"""

    def default(self, obj):
        # Handle ValidatorScore objects (both dataclass and Pydantic versions)
        if hasattr(obj, "__dict__"):
            # For dataclass objects
            if hasattr(obj, "__dataclass_fields__"):
                return asdict(obj)
            # For Pydantic BaseModel objects
            elif hasattr(obj, "dict"):
                return obj.dict()
            # For other objects with __dict__
            else:
                return obj.__dict__
        # Handle other non-serializable objects
        elif hasattr(obj, "to_dict"):
            return obj.to_dict()
        elif hasattr(obj, "_asdict"):
            return obj._asdict()
        # For any other case, convert to string
        else:
            return str(obj)


class SlotPhase(Enum):
    """Phases within each consensus slot"""

    TASK_ASSIGNMENT = "task_assignment"
    TASK_EXECUTION = "task_execution"
    CONSENSUS_SCORING = "consensus_scoring"
    METAGRAPH_UPDATE = "metagraph_update"


@dataclass
class SlotConfig:
    """Configuration for slot timing and phase boundaries"""

    slot_duration_minutes: float = 3.5  # Total slot duration (3.5 ph√∫t = 2+1+0.5)
    task_assignment_minutes: int = 2  # 0-2min: Task assignment + execution (merged)
    task_execution_minutes: int = 0  # DEPRECATED: Now merged into task_assignment
    consensus_minutes: int = 1  # 2-3min: Consensus scoring
    metagraph_update_seconds: int = 30  # 3-3.5min: Metagraph update (30 gi√¢y)

    # === FLEXIBLE CONSENSUS EXTENSIONS ===
    # Flexibility options
    allow_mid_slot_join: bool = True  # Allow validators to join mid-slot
    auto_extend_on_consensus: bool = True  # Auto-extend if consensus not reached
    max_auto_extension_seconds: int = (
        30  # Max auto-extension time (reduced for 3.5min cycles)
    )

    # Buffer times for flexibility (reduced for 3.5min cycles)
    task_deadline_buffer: int = 15  # 15s buffer for task completion
    consensus_deadline_buffer: int = 20  # 20s buffer for consensus
    metagraph_deadline_buffer: int = 5  # 5s buffer for metagraph

    # Adaptive timing
    adaptive_timing_enabled: bool = False  # Enable adaptive timing based on network
    min_validators_for_consensus: int = 2  # Minimum validators needed
    flexible_epoch_start: bool = False  # Use flexible epoch start instead of fixed

    def get_phase_boundaries(self) -> Dict[SlotPhase, Tuple[float, float]]:
        """Get start/end minutes for each phase (with merged task assignment + execution)"""
        # Convert metagraph_update_seconds to minutes
        metagraph_update_minutes = self.metagraph_update_seconds / 60.0

        # Calculate phase start/end times using merged assignment+execution
        task_assignment_end = float(
            self.task_assignment_minutes
        )  # Now includes execution time (2min)
        consensus_start = task_assignment_end  # Consensus starts after merged phase
        consensus_end = consensus_start + float(self.consensus_minutes)
        metagraph_start = consensus_end
        metagraph_end = metagraph_start + metagraph_update_minutes

        return {
            SlotPhase.TASK_ASSIGNMENT: (
                0.0,
                task_assignment_end,
            ),  # 0-2min (merged with execution)
            SlotPhase.TASK_EXECUTION: (
                0.0,
                task_assignment_end,
            ),  # DEPRECATED: Same as assignment for compatibility
            SlotPhase.CONSENSUS_SCORING: (consensus_start, consensus_end),  # 2-3min
            SlotPhase.METAGRAPH_UPDATE: (metagraph_start, metagraph_end),  # 3-3.5min
        }


class SlotCoordinator:
    """
    Coordinates slot-based consensus between validators

    This class provides the main coordination mechanism for ensuring validators
    synchronize their phase transitions and consensus activities.
    """

    def __init__(
        self,
        validator_uid: str,
        coordination_dir: str = "slot_coordination",
        slot_config: Optional[SlotConfig] = None,
    ):
        """
        Initialize SlotCoordinator

        Args:
            validator_uid: Unique identifier for this validator
            coordination_dir: Directory for coordination files
            slot_config: Optional slot configuration (uses default if None)
        """
        self.validator_uid = validator_uid
        self.coordination_dir = Path(coordination_dir)
        self.coordination_dir.mkdir(exist_ok=True)
        self.slot_config = slot_config or SlotConfig()

        logger.info(f"üîß SlotCoordinator initialized for {validator_uid}")
        logger.info(f"üîß Coordination dir: {self.coordination_dir.absolute()}")
        logger.info(
            f"üîß Slot config: {self.slot_config.slot_duration_minutes}min slots, {self.slot_config.task_assignment_minutes}min assignment"
        )

    def get_current_blockchain_slot(self) -> int:
        """Get current blockchain slot number based on timestamp"""
        current_time = int(time.time())
        slot_duration_seconds = self.slot_config.slot_duration_minutes * 60

        # FORCE FIXED EPOCH START FOR SYNC - disable dynamic detection
        # Always use fixed EPOCH_START to ensure all validators get same slot number
        epoch_start = EPOCH_START

        # Log for debugging slot sync
        slot_num = (current_time - epoch_start) // slot_duration_seconds
        logger.debug(
            f"üïê {self.validator_uid} Slot calculation: time={current_time}, epoch={epoch_start}, slot={slot_num}"
        )

        return slot_num

    def enable_flexible_mode(self, auto_detect_epoch: bool = True):
        """
        Enable flexible consensus mode with enhanced features.

        Args:
            auto_detect_epoch: Whether to auto-detect ongoing slots
        """
        logger.info(f"üîÑ {self.validator_uid} enabling flexible consensus mode")

        # Enable flexibility in config
        self.slot_config.allow_mid_slot_join = True
        self.slot_config.auto_extend_on_consensus = True
        self.slot_config.adaptive_timing_enabled = True
        # FORCE DISABLE flexible_epoch_start for slot sync
        self.slot_config.flexible_epoch_start = False

        # Skip dynamic epoch detection - use fixed EPOCH_START for validator sync
        logger.info(
            f"üîí {self.validator_uid} Using fixed epoch start for validator synchronization"
        )

    def _setup_dynamic_epoch_start(self):
        """Setup dynamic epoch start based on ongoing slots."""
        current_time = time.time()

        # Try to detect ongoing slot from coordination files
        active_slot = self._detect_active_slot_from_coordination()

        if active_slot is not None:
            # Calculate dynamic epoch start based on detected slot
            slot_duration_seconds = self.slot_config.slot_duration_minutes * 60
            self._dynamic_epoch_start = current_time - (
                active_slot * slot_duration_seconds
            )
            logger.info(
                f"üîÑ Dynamic epoch start set based on active slot {active_slot}"
            )
        else:
            # Use current time as epoch start
            self._dynamic_epoch_start = current_time
            logger.info("üîÑ Dynamic epoch start set to current time")

    def _detect_active_slot_from_coordination(self) -> Optional[int]:
        """Detect active slot by scanning coordination files"""
        coordination_files = list(self.coordination_dir.glob("slot_*_*.json"))

        if not coordination_files:
            return None

        # Find the most recent slot with active validators
        active_slots = set()
        current_time = time.time()

        for file_path in coordination_files:
            try:
                parts = file_path.stem.split("_")
                if len(parts) >= 2 and parts[0] == "slot":
                    slot_num = int(parts[1])

                    # Check if file is recent (within last 10 minutes)
                    if file_path.stat().st_mtime > current_time - 600:
                        active_slots.add(slot_num)

            except (ValueError, IndexError, OSError):
                continue

        return max(active_slots) if active_slots else None

    def get_slot_phase(self, slot_number: int) -> Tuple[SlotPhase, int, int]:
        """
        Get current phase within a slot and time remaining

        Args:
            slot_number: The slot number to check

        Returns:
            Tuple of (phase, seconds_into_phase, seconds_remaining_in_phase)
        """
        current_time = int(time.time())
        slot_duration_seconds = self.slot_config.slot_duration_minutes * 60

        slot_start_time = EPOCH_START + (slot_number * slot_duration_seconds)
        seconds_into_slot = current_time - slot_start_time
        minutes_into_slot = seconds_into_slot // 60  # For display
        minutes_into_slot_precise = seconds_into_slot / 60.0  # For calculations

        boundaries = self.slot_config.get_phase_boundaries()

        for phase, (start_min, end_min) in boundaries.items():
            if start_min <= minutes_into_slot_precise < end_min:
                seconds_remaining = int(
                    (end_min - minutes_into_slot_precise) * 60
                )  # Convert to seconds
                seconds_in_phase = int(
                    (minutes_into_slot_precise - start_min) * 60
                )  # Time in this phase in seconds
                return phase, seconds_in_phase, seconds_remaining

        # Default to task assignment if outside boundaries
        return SlotPhase.TASK_ASSIGNMENT, seconds_into_slot, 0

    def _get_time_until_next_phase(self, slot_number: int) -> Tuple[SlotPhase, int]:
        """Get next phase and seconds until it starts"""
        current_time = int(time.time())
        slot_duration_seconds = self.slot_config.slot_duration_minutes * 60

        slot_start_time = EPOCH_START + (slot_number * slot_duration_seconds)
        seconds_into_slot = current_time - slot_start_time
        minutes_into_slot_precise = seconds_into_slot / 60.0

        boundaries = self.slot_config.get_phase_boundaries()

        for phase, (start_min, end_min) in boundaries.items():
            if minutes_into_slot_precise < start_min:
                # This phase hasn't started yet
                time_until_phase = int(
                    (slot_start_time + start_min * 60) - current_time
                )
                return phase, time_until_phase

        # All phases passed, next phase is task assignment of next slot
        next_slot_start = slot_start_time + slot_duration_seconds
        time_until_next_slot = next_slot_start - current_time
        return SlotPhase.TASK_ASSIGNMENT, time_until_next_slot

    async def register_phase_entry(
        self, slot: int, phase: SlotPhase, extra_data: Dict = None
    ):
        """
        Register that this validator has entered a specific phase

        Args:
            slot: Slot number
            phase: Phase being entered
            extra_data: Optional additional data to store
        """
        logger.info(
            f"üîß REGISTER_PHASE_ENTRY: Validator {self.validator_uid} entering {phase.value} for slot {slot}"
        )
        logger.info(f"üîß Coordination dir: {self.coordination_dir.absolute()}")

        phase_file = (
            self.coordination_dir
            / f"slot_{slot}_{phase.value}_{self.validator_uid}.json"
        )

        logger.info(f"üîß Phase file will be: {phase_file.absolute()}")

        # Prepare phase data
        phase_data = {
            "validator_uid": self.validator_uid,
            "slot": slot,
            "phase": phase.value,
            "timestamp": time.time(),
            "extra_data": extra_data or {},
        }

        try:
            # Pre-validate the data by attempting to serialize it
            test_json = json.dumps(phase_data, cls=CustomJSONEncoder, indent=2)

            # Write to a temporary file first, then rename (atomic operation)
            temp_file = phase_file.with_suffix(".tmp")

            with open(temp_file, "w") as f:
                f.write(test_json)
                f.flush()  # Ensure data is written to disk

            # Atomic rename to final filename
            temp_file.rename(phase_file)

            logger.info(
                f"‚úÖ [V:{self.validator_uid}] Registered entry to {phase.value} phase of slot {slot}"
            )

        except Exception as e:
            logger.error(
                f"‚ùå [V:{self.validator_uid}] Failed to register phase entry: {e}"
            )

            # Clean up temp file if it exists
            temp_file = phase_file.with_suffix(".tmp")
            if temp_file.exists():
                try:
                    temp_file.unlink()
                except:
                    pass

            # If the error is related to serialization, try a simplified version
            try:
                # Create a simplified version without problematic objects
                simplified_data = {
                    "validator_uid": str(self.validator_uid),
                    "slot": int(slot),
                    "phase": str(phase.value),
                    "timestamp": float(time.time()),
                    "extra_data": self._simplify_extra_data(extra_data),
                }

                with open(phase_file, "w") as f:
                    json.dump(simplified_data, f, indent=2)
                    f.flush()

                logger.warning(
                    f"‚ö†Ô∏è [V:{self.validator_uid}] Used simplified data for phase entry due to serialization issues"
                )

            except Exception as e2:
                logger.error(
                    f"‚ùå [V:{self.validator_uid}] Failed even with simplified data: {e2}"
                )
                raise

    def _simplify_extra_data(self, extra_data: Dict) -> Dict:
        """
        Simplify extra_data to make it JSON serializable

        Args:
            extra_data: Original extra data that might contain complex objects

        Returns:
            Simplified data that can be JSON serialized
        """
        if not extra_data:
            return {}

        simplified = {}

        for key, value in extra_data.items():
            try:
                if value is None:
                    simplified[key] = None
                elif isinstance(value, (str, int, float, bool)):
                    simplified[key] = value
                elif isinstance(value, (list, tuple)):
                    # Simplify list/tuple items
                    simplified_list = []
                    for item in value:
                        if hasattr(item, "__dict__"):
                            # Convert objects to dict representation
                            if hasattr(item, "dict"):  # Pydantic
                                simplified_list.append(item.dict())
                            elif hasattr(item, "__dataclass_fields__"):  # dataclass
                                simplified_list.append(asdict(item))
                            else:
                                simplified_list.append(str(item))
                        elif isinstance(item, dict):
                            simplified_list.append(self._simplify_extra_data(item))
                        else:
                            simplified_list.append(str(item))
                    simplified[key] = simplified_list
                elif isinstance(value, dict):
                    # Recursively simplify nested dicts
                    simplified[key] = self._simplify_extra_data(value)
                elif hasattr(value, "__dict__"):
                    # Convert objects to dict representation
                    if hasattr(value, "dict"):  # Pydantic
                        simplified[key] = value.dict()
                    elif hasattr(value, "__dataclass_fields__"):  # dataclass
                        simplified[key] = asdict(value)
                    else:
                        simplified[key] = str(value)
                else:
                    # Fallback: convert to string
                    simplified[key] = str(value)

            except Exception as e:
                logger.debug(f"Error simplifying key {key}: {e}")
                simplified[key] = f"<error_serializing_{type(value).__name__}>"

        return simplified

    async def wait_for_phase_consensus(
        self, slot: int, phase: SlotPhase, timeout: int = 60
    ) -> List[str]:
        """
        Wait for majority of validators to enter the same phase

        Args:
            slot: Slot number
            phase: Phase to wait for
            timeout: Maximum time to wait in seconds

        Returns:
            List of validator UIDs that are ready
        """
        start_time = time.time()
        logger.info(
            f"‚è≥ [V:{self.validator_uid}] Waiting for validators to enter {phase.value} phase of slot {slot}"
        )

        while time.time() - start_time < timeout:
            ready_validators = self._get_ready_validators(slot, phase)

            logger.debug(
                f"üîç [V:{self.validator_uid}] Slot {slot} {phase.value}: "
                f"{len(ready_validators)}/{len(EXPECTED_VALIDATORS)} validators ready: {ready_validators}"
            )

            # Need majority for consensus
            if len(ready_validators) >= MAJORITY_THRESHOLD:
                logger.info(
                    f"‚úÖ [V:{self.validator_uid}] Sufficient validators in {phase.value} phase: {ready_validators}"
                )
                return ready_validators

            await asyncio.sleep(CONSENSUS_CHECK_INTERVAL)

        logger.warning(
            f"‚ö†Ô∏è [V:{self.validator_uid}] Timeout waiting for {phase.value} phase. "
            f"Only {len(ready_validators)} ready"
        )
        return ready_validators

    async def wait_for_phase_consensus_flexible(
        self, slot: int, phase: SlotPhase, timeout: int = 60
    ) -> List[str]:
        """
        Flexible version of wait_for_phase_consensus with enhanced features.

        This method provides:
        - Dynamic timeout adjustment based on network conditions
        - Auto-extension if close to consensus
        - Graceful handling of fewer validators
        - Mid-slot join support

        Args:
            slot: Slot number
            phase: Phase to wait for
            timeout: Base timeout (may be extended)

        Returns:
            List of validator UIDs that have entered the phase
        """
        start_time = time.time()
        original_timeout = timeout

        # Apply buffer time if configured
        if phase == SlotPhase.CONSENSUS_SCORING:
            timeout += self.slot_config.consensus_deadline_buffer
        elif phase == SlotPhase.TASK_EXECUTION:
            timeout += self.slot_config.task_deadline_buffer
        elif phase == SlotPhase.METAGRAPH_UPDATE:
            timeout += self.slot_config.metagraph_deadline_buffer

        logger.info(
            f"‚è≥ [V:{self.validator_uid}] Flexible wait for {phase.value} phase of slot {slot} "
            f"(timeout: {timeout}s, buffer: {timeout - original_timeout}s)"
        )

        last_ready_count = 0
        auto_extension_used = False

        while time.time() - start_time < timeout:
            ready_validators = self._get_ready_validators(slot, phase)
            current_ready_count = len(ready_validators)

            logger.debug(
                f"üîç [V:{self.validator_uid}] Slot {slot} {phase.value}: "
                f"{current_ready_count} validators ready: {ready_validators}"
            )

            # Check for majority consensus (traditional threshold)
            if current_ready_count >= MAJORITY_THRESHOLD:
                logger.info(
                    f"‚úÖ [V:{self.validator_uid}] Consensus reached in {phase.value} phase: {ready_validators}"
                )
                return ready_validators

            # Flexible consensus: Accept lower threshold if configured
            if (
                self.slot_config.allow_mid_slot_join
                and current_ready_count >= self.slot_config.min_validators_for_consensus
            ):

                # Check if all detected active validators are ready
                all_active_validators = self._get_all_active_validators_in_slot(slot)
                if all_active_validators and current_ready_count >= len(
                    all_active_validators
                ):
                    logger.info(
                        f"‚úÖ [V:{self.validator_uid}] All active validators ready for {phase.value}: {ready_validators}"
                    )
                    return ready_validators

            # Hard timing boundary check - never extend beyond phase end time
            current_time = time.time()
            current_slot = self.get_current_blockchain_slot()
            slot_start_time = EPOCH_START + (
                current_slot * self.slot_config.slot_duration_minutes * 60
            )
            time_into_slot = current_time - slot_start_time
            phase_boundaries = self.slot_config.get_phase_boundaries()

            # Calculate time until phase end
            time_until_phase_end = 999999  # Default large value
            if phase in phase_boundaries:
                phase_start_min, phase_end_min = phase_boundaries[phase]
                phase_end_time = slot_start_time + (phase_end_min * 60)
                time_until_phase_end = phase_end_time - current_time

                # If less than 5 seconds until phase end, force transition
                if time_until_phase_end <= 5:
                    logger.warning(
                        f"‚è∞ [V:{self.validator_uid}] Hard timing boundary reached for {phase.value} "
                        f"({time_until_phase_end:.1f}s remaining) - forcing transition"
                    )
                    break

            # Auto-extension logic (only if not approaching hard boundary)
            if (
                self.slot_config.auto_extend_on_consensus
                and not auto_extension_used
                and current_ready_count > 0
                and current_ready_count < MAJORITY_THRESHOLD
                and time.time() - start_time > timeout * 0.8
                and time_until_phase_end > 10  # Only extend if >10s until phase end
            ):  # 80% of timeout passed

                # Limit extension to not exceed phase boundary
                max_extension = min(
                    self.slot_config.max_auto_extension_seconds,
                    60,
                    int(time_until_phase_end - 5),  # Leave 5s buffer
                )

                if max_extension > 0:
                    timeout += max_extension
                    auto_extension_used = True

                    logger.info(
                        f"üîÑ [V:{self.validator_uid}] Auto-extending {phase.value} wait by {max_extension}s "
                        f"({current_ready_count} validators ready, {time_until_phase_end:.1f}s until phase end)"
                    )
                else:
                    logger.warning(
                        f"‚ö†Ô∏è [V:{self.validator_uid}] Auto-extension skipped - too close to phase boundary "
                        f"({time_until_phase_end:.1f}s remaining)"
                    )

            # Track progress
            if current_ready_count != last_ready_count:
                logger.info(
                    f"üìà [V:{self.validator_uid}] Validator count changed: {last_ready_count} ‚Üí {current_ready_count}"
                )
                last_ready_count = current_ready_count

            await asyncio.sleep(CONSENSUS_CHECK_INTERVAL)

        # Final assessment
        final_ready_validators = self._get_ready_validators(slot, phase)

        if len(final_ready_validators) > 0:
            logger.info(
                f"‚ö†Ô∏è [V:{self.validator_uid}] Flexible consensus proceeding with {len(final_ready_validators)} validators "
                f"for {phase.value} phase"
            )
        else:
            logger.warning(
                f"‚ùå [V:{self.validator_uid}] No validators ready for {phase.value} phase after flexible timeout"
            )

        return final_ready_validators

    def _get_all_active_validators_in_slot(self, slot: int) -> List[str]:
        """Get all validators active in the given slot across all phases"""
        active_validators = set()

        # Scan all coordination files for this slot
        pattern = f"slot_{slot}_*.json"
        coordination_files = list(self.coordination_dir.glob(pattern))

        for file_path in coordination_files:
            try:
                with open(file_path, "r") as f:
                    data = json.load(f)
                    if data.get("slot") == slot:
                        validator_uid = data.get("validator_uid")
                        if validator_uid:
                            active_validators.add(validator_uid)
            except:
                continue

        return list(active_validators)

    def _get_ready_validators(self, slot: int, phase: SlotPhase) -> List[str]:
        """Get list of validators ready for given slot and phase"""
        ready_validators = []

        # Dynamic validator detection: scan for all phase files matching the pattern
        pattern = f"slot_{slot}_{phase.value}_*.json"

        try:
            for phase_file in self.coordination_dir.glob(pattern):
                try:
                    with open(phase_file, "r") as f:
                        data = json.load(f)
                        if (
                            data.get("slot") == slot
                            and data.get("phase") == phase.value
                        ):
                            validator_uid = data.get("validator_uid")
                            if validator_uid and validator_uid not in ready_validators:
                                ready_validators.append(validator_uid)
                except Exception as e:
                    logger.debug(f"Error reading phase file {phase_file}: {e}")
        except Exception as e:
            logger.debug(f"Error scanning coordination directory: {e}")

        # Fallback to EXPECTED_VALIDATORS for backward compatibility
        if not ready_validators:
            for validator_uid in EXPECTED_VALIDATORS:
                phase_file = (
                    self.coordination_dir
                    / f"slot_{slot}_{phase.value}_{validator_uid}.json"
                )
                if phase_file.exists():
                    try:
                        with open(phase_file, "r") as f:
                            data = json.load(f)
                            if (
                                data.get("slot") == slot
                                and data.get("phase") == phase.value
                            ):
                                ready_validators.append(validator_uid)
                    except Exception as e:
                        logger.debug(f"Error reading phase file {phase_file}: {e}")

        return ready_validators

    async def synchronized_phase_transition(
        self, slot: int, current_phase: SlotPhase, next_phase: SlotPhase
    ) -> bool:
        """
        Coordinate synchronized transition from current phase to next phase

        Args:
            slot: Slot number
            current_phase: Current phase
            next_phase: Phase to transition to

        Returns:
            True if transition was successful
        """
        logger.info(
            f"üîÑ [V:{self.validator_uid}] Initiating synchronized transition: "
            f"{current_phase.value} ‚Üí {next_phase.value}"
        )

        try:
            # Step 1: Wait for all validators to finish current phase
            await self.wait_for_phase_consensus(slot, current_phase)

            # Step 2: Wait for the correct time to start next phase
            next_phase_start, seconds_until = self._get_time_until_next_phase(slot)

            if next_phase_start == next_phase and seconds_until > 0:
                logger.info(
                    f"‚è∞ [V:{self.validator_uid}] Waiting {seconds_until}s for {next_phase.value} phase"
                )
                await asyncio.sleep(seconds_until)

            # Step 3: Register entry to next phase
            await self.register_phase_entry(slot, next_phase)

            # Step 4: Wait for other validators to join next phase
            ready_validators = await self.wait_for_phase_consensus(slot, next_phase)

            if len(ready_validators) >= MAJORITY_THRESHOLD:
                logger.info(
                    f"‚úÖ [V:{self.validator_uid}] Synchronized transition completed: "
                    f"{current_phase.value} ‚Üí {next_phase.value}"
                )
                return True
            else:
                logger.warning(
                    f"‚ö†Ô∏è [V:{self.validator_uid}] Failed synchronized transition: insufficient validators"
                )
                return False

        except Exception as e:
            logger.error(
                f"‚ùå [V:{self.validator_uid}] Error in synchronized transition: {e}"
            )
            return False

    async def enforce_task_assignment_cutoff(self, slot: int) -> bool:
        """
        Ensure all validators stop task assignment at the same time

        Args:
            slot: Slot number

        Returns:
            True if cutoff was enforced successfully
        """
        logger.info(
            f"üõë [V:{self.validator_uid}] Enforcing task assignment cutoff for slot {slot}"
        )

        try:
            # Get current phase
            current_phase, minutes_into_slot, minutes_remaining = self.get_slot_phase(
                slot
            )

            if current_phase != SlotPhase.TASK_ASSIGNMENT:
                logger.info(
                    f"‚úÖ [V:{self.validator_uid}] Already past task assignment phase"
                )
                return True

            # Calculate exact cutoff time
            slot_start_time = EPOCH_START + (
                slot * self.slot_config.slot_duration_minutes * 60
            )
            cutoff_time = slot_start_time + (
                self.slot_config.task_assignment_minutes * 60
            )
            current_time = int(time.time())

            if current_time < cutoff_time:
                wait_time = cutoff_time - current_time
                logger.info(
                    f"‚è∞ [V:{self.validator_uid}] Waiting {wait_time}s for task assignment cutoff"
                )
                await asyncio.sleep(wait_time)

            # Register that we've stopped task assignment
            await self.register_phase_entry(
                slot, SlotPhase.TASK_EXECUTION, {"task_assignment_stopped": True}
            )

            logger.info(
                f"‚úÖ [V:{self.validator_uid}] Task assignment cutoff enforced for slot {slot}"
            )
            return True

        except Exception as e:
            logger.error(
                f"‚ùå [V:{self.validator_uid}] Error enforcing task assignment cutoff: {e}"
            )
            return False

    async def coordinate_consensus_round(
        self, slot: int, local_scores: Dict[str, float]
    ) -> Dict[str, float]:
        """
        Coordinate consensus round with other validators

        Args:
            slot: Slot number
            local_scores: This validator's local scores

        Returns:
            Dictionary of consensus scores (averaged across validators)
        """
        logger.info(
            f"ü§ù [V:{self.validator_uid}] Starting consensus coordination for slot {slot}"
        )

        try:
            # Step 1: Register consensus readiness with scores
            await self.register_phase_entry(
                slot, SlotPhase.CONSENSUS_SCORING, {"scores": local_scores}
            )

            # Step 2: Wait for other validators to be ready
            ready_validators = await self.wait_for_phase_consensus(
                slot, SlotPhase.CONSENSUS_SCORING
            )

            if len(ready_validators) < MAJORITY_THRESHOLD:
                logger.warning(
                    f"‚ö†Ô∏è [V:{self.validator_uid}] Insufficient validators for consensus: {len(ready_validators)}"
                )
                return {}

            # Step 3: Calculate consensus scores
            consensus_scores = self._calculate_consensus_scores(slot, ready_validators)

            logger.info(
                f"‚úÖ [V:{self.validator_uid}] Consensus completed for slot {slot}: {len(consensus_scores)} scores"
            )
            return consensus_scores

        except Exception as e:
            logger.error(
                f"‚ùå [V:{self.validator_uid}] Error in consensus coordination: {e}"
            )
            return {}

    def _calculate_consensus_scores(
        self, slot: int, participating_validators: List[str]
    ) -> Dict[str, float]:
        """Calculate consensus scores from all participating validators"""
        all_scores = {}

        # Collect scores from all participating validators
        for validator_uid in participating_validators:
            score_file = (
                self.coordination_dir
                / f"slot_{slot}_consensus_scoring_{validator_uid}.json"
            )
            if score_file.exists():
                try:
                    with open(score_file, "r") as f:
                        data = json.load(f)
                        scores = data.get("extra_data", {}).get("scores", {})

                        # Handle both dict and list formats
                        if isinstance(scores, dict):
                            # Standard dict format: {miner_uid: score}
                            for miner_uid, score in scores.items():
                                if miner_uid not in all_scores:
                                    all_scores[miner_uid] = []
                                all_scores[miner_uid].append(score)
                        elif isinstance(scores, list):
                            # List format: [{"miner_uid": "...", "score": 0.5}]
                            for score_entry in scores:
                                if (
                                    isinstance(score_entry, dict)
                                    and "miner_uid" in score_entry
                                    and "score" in score_entry
                                ):
                                    miner_uid = score_entry["miner_uid"]
                                    score = score_entry["score"]
                                    if miner_uid not in all_scores:
                                        all_scores[miner_uid] = []
                                    all_scores[miner_uid].append(score)
                        else:
                            logger.warning(
                                f"Invalid scores format from {validator_uid}: {type(scores)}"
                            )

                except Exception as e:
                    logger.error(f"Error reading scores from {validator_uid}: {e}")

        # Calculate consensus (simple average)
        consensus_scores = {}
        for miner_uid, score_list in all_scores.items():
            if score_list:
                consensus_score = sum(score_list) / len(score_list)
                consensus_scores[miner_uid] = consensus_score
                logger.info(
                    f"üìä [V:{self.validator_uid}] Miner {miner_uid}: "
                    f"{consensus_score:.4f} (from {len(score_list)} validators)"
                )

        return consensus_scores

    def cleanup_old_coordination_files(self, current_slot: int, keep_slots: int = 5):
        """
        Clean up old coordination files to prevent directory bloat

        Args:
            current_slot: Current slot number
            keep_slots: Number of recent slots to keep files for
        """
        try:
            cleaned_count = 0
            for file_path in self.coordination_dir.glob("slot_*.json"):
                try:
                    # Extract slot number from filename
                    parts = file_path.name.split("_")
                    if len(parts) >= 2:
                        slot_num = int(parts[1])
                        if slot_num < current_slot - keep_slots:
                            file_path.unlink()
                            cleaned_count += 1
                except (ValueError, IndexError):
                    continue

            if cleaned_count > 0:
                logger.debug(f"Cleaned up {cleaned_count} old coordination files")

        except Exception as e:
            logger.debug(f"Error cleaning up coordination files: {e}")
